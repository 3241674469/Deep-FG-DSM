
# Deep-FG-DSM:Fine-Grained DSM for High-resolution UAV Imagery Based on Deep Implicit Occupancy Networks

This repository provides the code to train and evaluate Deep-FG-DSM: a method for generating fine-grained DSMs using raw noisy and sparse point clouds and ortho-images obtained via photogrammetric processing from high-resolution UAV images.

The code will be available soon, so please stay tuned! Unfortunately, due to certain regulations, the UAVIIR dataset cannot be publicly released. However, it can be provided upon request. In this README file, I will provide detailed instructions on how to create the dataset used in this paper.



![Method review](https://i.imgur.com/osjR3TY.png)

  [[paper link]](https://isprs-archives.copernicus.org/articles/XLVIII-1-2024/209/2024/)

## Authors

- [Yongmao Hou, Haibo Zhang, Xin Wang*, Zongqian Zhan](http://main.sgg.whu.edu.cn/info/1392/1204.htm)


## UAV Dataset

The images of UAVIIR are from the WHU MVS/Stereo dataset, which is originally used for large-scale and high-resolution Multi-View Stereo (MVS) reconstruction. 

The whole study area within the dataset covers approximately 6.7×2.2 km in Meidan County, Guizhou Province, China. This county comprises densely populated residential and high-rise buildings, sparse factories, forested mountain ranges, as well as some exposed ground and rivers. Images are captured at an altitude of above 550 meters, with a ground sample distance (GSD) of approximately 10 cm. In total, 1,776 images (5376×5376) were acquired across 16 flight strips, providing 90% forward overlap and 80% side overlap. 

We divided the entire study area into 8 strips, as shown in Fig.5, the size of each strip is approximately 2.2km × 0.8km. Strips 2, 4, and 7 are used as training set (containing varying degrees of land features, including buildings, vegetation, and water bodies which are expected to enhance the model's generalization capability), strip 6 serves as validation set, and strip 5 is designated as the test set. The remaining strips 1, 3, and 8 is also used as test sets to assess the model's generalization capability. 

![Study area](https://i.imgur.com/SYWFDTy.png)

The popular commercial software ContextCapture (CC) is used for processing and modelling our aerial images. Initially, high-resolution aerial images were imported, followed by preprocessing steps such as image registration, noise removal, and radiometric correction. Subsequently, aerial triangulation was performed to generate point clouds, ortho-images, precise 3D mesh models and Digital Surface Models (DSM) can be automatically generated. During this procedure, point clouds were obtained, and then simplifying and random Gaussian noise addition were applied to generate sparse point clouds and noisy point clouds, respectively. The UAVIIR dataset includes four types of point clouds with different sampling resolution and four types of point clouds with different levels of Gaussian noise added.

To train our model, it's essential to establish the relationship between any point in space and the target surface. Points inside the target surface are assigned an occupancy value of 1, while points outside the surface are assigned a value of 0. Based on this, we sample query points with known occupancy values in the space of the 3D mesh model generated by CC to supervise our training. However, uniform sampling of points in space may result in most points being far from the target surface, potentially introducing unnecessary external influence on the network. Conversely, sampling only near the iso-surface may lead to overfitting issues. Therefore, we adopt a combined approach of uniform sampling and surface sampling. Specifically, we first randomly sample points on the target surface and add zero-mean Gaussian random noise with σ=0.4m. Then, we perform uniform sampling in space. Specifically, we set the resolution of surface sampling to 0.4m and the resolution of uniform spatial sampling to 3m. The ratio of surface sampling points to uniform spatial sampling points is approximately 2:1. This sampling method effectively preserves information about the target surface while avoiding overfitting issues.

![UAVIIR dataset creation](https://i.imgur.com/zeQR3ap.png)
## Contact

If you have questions, please contact [Xin Wang](http://main.sgg.whu.edu.cn/info/1392/1204.htm) and [Yongmao Hou](https://github.com/3241674469).


## Acknowledgements
In this project we use (parts of) the official implementations of the following works:
 - [IMPLICITY](https://github.com/prs-eth/ImpliCity)
 - [Convolutional Occupancy Networks](https://github.com/autonomousvision/convolutional_occupancy_networks)
 - [PIFu](https://github.com/shunsukesaito/PIFu)
 - [PointNet++](https://github.com/yanx27/Pointnet_Pointnet2_pytorch)

We thank the respective authors for open sourcing and maintenance.

